{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vIpadAOEQnpe"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6lnrAQpQMbVy"
      },
      "outputs": [],
      "source": [
        "# The first thing is to define the phi matrix and the initial weights\n",
        "phi = np.array([[1,4,2,1,2,1],\n",
        "              [4,1,2,2,1,1],\n",
        "              [9,0,0,3,0,1],\n",
        "              [1,9,3,1,3,1],\n",
        "              [4,16,8,2,4,1],\n",
        "              [0,25,0,0,5,1]])\n",
        "\n",
        "y = np.array([\n",
        "    [9],\n",
        "    [12],\n",
        "    [19],\n",
        "    [12],\n",
        "    [21],\n",
        "    [16]\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ash82SaTQ_EC",
        "outputId": "9aeb9917-d294-4ae5-b740-1839752c7bd2"
      },
      "outputs": [],
      "source": [
        "# Let's give the user the chance to enter the learning rate and the\n",
        "# number of iterations\n",
        "lr = float(input('Enter the learning rate\\n'))\n",
        "niter = int(input('Enter the number of iterations\\n'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a114d75",
        "outputId": "540b3b7c-c97d-4a3b-d267-e1b50e204ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SGD learned coefficients (no bias column): [1.5839327  0.32568256 0.11656932 1.22078889 1.35566355]\n",
            "SGD intercept: 1.1142373079586312\n",
            "Predictions (SGD): [ 8.16615487 11.80603064 19.03199829 11.26680052 21.45767556]\n"
          ]
        }
      ],
      "source": [
        "# --- sklearn: Gradient Descent with SGDRegressor (mixed polynomial features) ---\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "import numpy as np\n",
        "\n",
        "# In this notebook, phi columns are [x1^2, x2^2, x1*x2, x1, x2, 1]\n",
        "# We'll pass all feature columns except the bias to sklearn\n",
        "X = phi[:, :-1]            # drop the bias column (last column)\n",
        "y_vec = y.flatten()          # sklearn expects a 1-D target\n",
        "\n",
        "# Reuse your inputs lr (learning rate) and niter (iterations)\n",
        "sgd = SGDRegressor(\n",
        "    loss=\"squared_error\",\n",
        "    penalty=None,          # pure GD on MSE, no regularization\n",
        "    alpha=0.0,\n",
        "    learning_rate=\"constant\",\n",
        "    eta0=lr,               # step size\n",
        "    max_iter=niter,\n",
        "    tol=None,              # run full niter\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "sgd.fit(X, y_vec)\n",
        "\n",
        "# Collect learned parameters and print compact form\n",
        "coef = sgd.coef_\n",
        "intercept = sgd.intercept_[0]\n",
        "print(\"SGD learned coefficients (no bias column):\", coef)\n",
        "print(\"SGD intercept:\", intercept)\n",
        "\n",
        "# For downstream cells that expect full phi @ w style predictions, we set:\n",
        "# final_predictions to the SGD predictions to allow existing plotting/printing to work.\n",
        "final_predictions = sgd.predict(X).reshape(-1, 1)\n",
        "print('Predictions (SGD):', final_predictions[:5].ravel())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gCelP1TS64Dp"
      },
      "outputs": [],
      "source": [
        "# # To see the loss\n",
        "# from sklearn.linear_model import SGDRegressor\n",
        "# import numpy as np\n",
        "\n",
        "# X = phi[:, :-1]\n",
        "# y_vec = y.ravel()\n",
        "\n",
        "# sgd = SGDRegressor(\n",
        "#     loss=\"squared_error\",\n",
        "#     penalty=None,\n",
        "#     alpha=0.0,\n",
        "#     learning_rate=\"constant\",\n",
        "#     eta0=lr,\n",
        "#     max_iter=1,        # one epoch per partial_fit\n",
        "#     warm_start=True,   # keep weights between calls\n",
        "#     tol=None,\n",
        "#     random_state=0\n",
        "# )\n",
        "\n",
        "# loss_hist = []\n",
        "# for i in range(niter):\n",
        "#     sgd.partial_fit(X, y_vec)\n",
        "#     preds = sgd.predict(X)\n",
        "#     loss = np.mean((preds - y_vec)**2)\n",
        "#     loss_hist.append(loss)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ds",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
